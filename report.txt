Harry Roscoe (har14) and Sahil Parekh (sp5714) Output Analysis

For our analysis, we attempted to run these systems on both our Cloudstack
virtual machine and lab machines. We noticed that on lab machines, each process
appears to freely send and receive but on a VM, they seem to get equal time to
do their activities. We believe this is due to the way BEAM reacts with its host
machine e.g. perhaps different scheduling systems are employed.

%%% SYSTEM 1 %%%

    1000 max messages, 3 second timeout:

    5: [{1000,1000},{1000,1000},{1000,1000},{1000,1000},{1000,1000}]
    2: [{1000,1000},{1000,1000},{1000,1000},{1000,1000},{1000,1000}]
    3: [{1000,1000},{1000,1000},{1000,1000},{1000,1000},{1000,1000}]
    1: [{1000,1000},{1000,1000},{1000,1000},{1000,1000},{1000,1000}]
    4: [{1000,1000},{1000,1000},{1000,1000},{1000,1000},{1000,1000}]

    0 max messages, 3 second timeout:

    2: [{995035,708542},{995035,995035},{995035,699823},{995035,824834},{995035,780366}]
    5: [{780368,708542},{780368,995035},{780368,699822},{780368,824835},{780368,780367}]
    3: [{699823,708542},{699823,995035},{699823,699822},{699823,824834},{699823,780366}]
    4: [{824835,708542},{824835,995035},{824835,699822},{824835,824834},{824835,780366}]
    1: [{708542,708542},{708542,995034},{708542,699823},{708542,824834},{708542,780365}]

    The tuples seem to match up as the number of messages P sends to Q is roughly
    identical to the number of messages Q sends to P in all cases. In some cases
    this number is off by one, possibly due to the timeout occurring before the
    message reaches the queue of the receiving process. For all our systems, we
    terminate immediately upon the timeout and therefore do not process any
    messages that arrive in the queue after the 'stop' message. In these runs,
    1 second is enough to process all the messages in the queue.



%%% SYSTEM 2 %%%

    100 max messages, 1 sec timeout:

    2: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    1: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    3: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    4: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    5: [{100,100},{100,100},{100,100},{100,100},{100,100}]

    0 max messages, 1 sec timeout:

    2: [{161790,28587},{161790,30675},{161790,49722},{161790,23151},{161790,37724}]
    1: [{227253,35392},{227253,30919},{227253,54578},{227253,30619},{227253,38932}]
    3: [{197278,28587},{197278,30864},{197278,50022},{197278,23519},{197278,37927}]
    4: [{205018,28587},{205018,29243},{205018,49016},{205018,19306},{205018,34849}]
    5: [{154754,27046},{154754,27541},{154754,47834},{154754,15775},{154754,31642}]

    When max messages is set, all messages are received in time and correctly,
    but with unlimited message sending, processes receive much fewer
    messages. We can see that time is the limiting factor here - if we run a
    test with max messages = 250,000 and a much longer timeout, take 10s, we get:

    2: [{250000,250000},{250000,250000},{250000,250000},{250000,250000},{250000,250000}]
    4: [{250000,250000},{250000,250000},{250000,250000},{250000,250000},{250000,250000}]
    3: [{250000,250000},{250000,250000},{250000,250000},{250000,250000},{250000,250000}]
    1: [{250000,250000},{250000,250000},{250000,250000},{250000,250000},{250000,250000}]
    5: [{250000,250000},{250000,250000},{250000,250000},{250000,250000},{250000,250000}]



%%% SYSTEM 3 %%%

    100 max messages, 1 sec timeout:

    2: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    5: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    4: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    3: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    1: [{100,100},{100,100},{100,100},{100,100},{100,100}]

    0 max messages, 1 sec timeout:

    1: [{598084,2282},{598084,3316},{598084,2898},{598084,6429},{598084,4851}]
    4: [{574979,914},{574979,766},{574979,1238},{574979,4789},{574979,2900}]
    5: [{494539,2770},{494539,4255},{494539,3558},{494539,7057},{494539,5322}]
    2: [{541431,4039},{541431,6110},{541431,5104},{541431,8666},{541431,6672}]
    3: [{595526,1072},{595526,1081},{595526,1423},{595526,5023},{595526,3226}]

    Sending rate should be 5x that of system 2, as we are now broadcasting to every
    other component, but the addition of the BEB and its own message queue
    further delays transmission and so the increase is roughly 3x.
    The number of received messages is even lower due to the addition of the
    BEB and so 1 second is certainly not enough time to process every
    sent message in all of the message queues, resulting in increased latency.



%%% SYSTEM 4 %%%

For system 4, we simply added a reliability parameter to the p2p link and used
Erlang's random number generator to determine whether or not to pass the message
on.

    100 max messages, 1 sec timeout -

        100 reliability:

        3: [{100,100},{100,100},{100,100},{100,100},{100,100}]
        1: [{100,100},{100,100},{100,100},{100,100},{100,100}]
        2: [{100,100},{100,100},{100,100},{100,100},{100,100}]
        5: [{100,100},{100,100},{100,100},{100,100},{100,100}]
        4: [{100,100},{100,100},{100,100},{100,100},{100,100}]

        50 reliability:
        1: [{100,46},{100,56},{100,42},{100,49},{100,55}]
        2: [{100,48},{100,46},{100,51},{100,56},{100,52}]
        4: [{100,47},{100,43},{100,49},{100,54},{100,50}]
        3: [{100,47},{100,51},{100,52},{100,50},{100,47}]
        5: [{100,58},{100,46},{100,56},{100,50},{100,47}]

        0 reliability:

        3: [{100,0},{100,0},{100,0},{100,0},{100,0}]
        1: [{100,0},{100,0},{100,0},{100,0},{100,0}]
        2: [{100,0},{100,0},{100,0},{100,0},{100,0}]
        5: [{100,0},{100,0},{100,0},{100,0},{100,0}]
        4: [{100,0},{100,0},{100,0},{100,0},{100,0}]

    These numbers are very much in line with expectations with regards to the
    reliability. As the message queue is quite short, we can see the reliability
    quite easily.

    0 max messages, 1 sec timeout -

        100 reliability:

        5: [{546861,1079},{546861,2991},{546861,1433},{546861,1183},{546861,2177}]
        3: [{677754,230},{677754,704},{677754,367},{677754,325},{677754,504}]
        1: [{328454,5123},{328454,9002},{328454,5245},{328454,4106},{328454,7491}]
        2: [{398845,2829},{398845,5388},{398845,2778},{398845,2212},{398845,4047}]
        4: [{626446,593},{626446,1953},{626446,728},{626446,621},{626446,1252}]

        50 reliability:

        1: [{507150,2696},{507150,1395},{507150,3533},{507150,356},{507150,1985}]
        3: [{445926,1742},{445926,899},{445926,2231},{445926,229},{445926,933}]
        5: [{515686,3476},{515686,1784},{515686,4705},{515686,792},{515686,3509}]
        4: [{333729,5560},{333729,2769},{333729,7053},{333729,1502},{333729,6248}]
        2: [{282583,6334},{282583,2932},{282583,7851},{282583,1588},{282583,6343}]

        0 reliability:

        5: [{872562,0},{872562,0},{872562,0},{872562,0},{872562,0}]
        3: [{510328,0},{510328,0},{510328,0},{510328,0},{510328,0}]
        2: [{417658,0},{417658,0},{417658,0},{417658,0},{417658,0}]
        1: [{882701,0},{882701,0},{882701,0},{882701,0},{882701,0}]
        4: [{295172,0},{295172,0},{295172,0},{295172,0},{295172,0}]

    These numbers do not appear to observe the reliability parameter set, but
    as we've seen from prior tests, this is due to the overflooding of broadcast
    messages. 1 second is not long enough to clear out the message queue.
    Interestingly, we can also spot a trend where the more a process sends, the
    less it receives.



%%% SYSTEM 5 %%%

In our previous systems, we have a timer clause which sends a 'stop' message to
all processes to stop and print the output. For system 5, we simply set this timer
to 5ms.

    100 max messages, 1 sec timeout, 5ms crash:

    3: [{100,0},{100,0},{100,0},{100,0},{100,0}]
    4: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    5: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    2: [{100,100},{100,100},{100,100},{100,100},{100,100}]
    1: [{100,100},{100,100},{100,100},{100,100},{100,100}]

    0 max messages, 1 sec timeout, 5ms crash:

    3: [{6102,0},{6102,0},{6102,0},{6102,0},{6102,0}]
    4: [{584798,6805},{584798,3891},{584798,3692},{584798,2981},{584798,5867}]
    1: [{674636,8038},{674636,4322},{674636,4397},{674636,3325},{674636,7703}]
    5: [{439280,3623},{439280,2965},{439280,2165},{439280,1536},{439280,2456}]
    2: [{619523,2189},{619523,2639},{619523,1496},{619523,1247},{619523,1590}]

    As expected, process 3 sends the few messages it can during its given life,
    and then dies while the other processes continue. As a consequence, the
    other processes receive a fewer percentage of packets from process 3. We can
    also compare different crash times -

    0 max messages, 1 sec timeout, 300ms crash:

    3: [{95916,546},{95916,167},{95916,189},{95916,170},{95916,127}]
    4: [{419553,6394},{419553,5864},{419553,5523},{419553,6166},{419553,4014}]
    2: [{709350,268},{709350,80},{709350,105},{709350,81},{709350,67}]
    1: [{636331,2208},{636331,762},{636331,709},{636331,665},{636331,534}]
    5: [{382366,2588},{382366,1319},{382366,1305},{382366,1321},{382366,926}]

    Given a longer time until crash, process 3 sends more messages and manages
    to a receive a few as well before crashing.

%%% SYSTEM 6 %%%

For system 6, we didn't keep the lossyp2p link as in system 5 because the
reliability will always be 100 - this is identical to the regular p2p component.

    0 max messages, 1 sec timeout, 5ms crash:

    3: [{431,0},{431,0},{431,0},{431,0},{431,0}]
    2: [{234837,256},{234837,881},{234837,324},{234837,379},{234837,404}]
    1: [{251978,718},{251978,2027},{251978,431},{251978,489},{251978,531}]
    4: [{465575,194},{465575,650},{465575,376},{465575,376},{465575,404}]
    5: [{165791,413},{165791,1404},{165791,431},{165791,379},{165791,428}]

    The eager reliable broadcast seems to be much better at getting the messages
    that process 3 sent to the recipients. Process 3 manages to send 431
    messages in its lifetime and most of these seem to get received by the final
    timeout.
    The number of messages received is the lowest of all runs. We believe this is
    because messages now have to go through all of the queues of the various
    subcomponents (PL, BEB, RB) and back up to the recipient. This means more time
    is spent in transmission and so fewer messages are received if we impose a
    short timeout. If we set a max_messages, this backlog is generally accounted
    for given a long enough timeout.

    For another test, we set max messages to 10,000 and timeout to 10s:

    3: [{325,9},{325,8},{325,3},{325,11},{325,9}]
    1: [{10000,1018},{10000,8463},{10000,325},{10000,1538},{10000,148}]
    4: [{10000,1055},{10000,9779},{10000,325},{10000,1661},{10000,147}]
    2: [{10000,1004},{10000,7914},{10000,325},{10000,1526},{10000,147}]
    5: [{10000,5547},{10000,10000},{10000,325},{10000,7670},{10000,857}]

    This shows that given enough time, all of 3's messages will eventually be
    processed. We can also see that on this occasion, process 2 gets a lot more
    time on the CPU than process 5.
